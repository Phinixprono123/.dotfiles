import discord
from discord.ext import commands
import requests
import json
import os
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()
TOKEN = os.getenv("DISCORD_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Setup Discord bot intents and create the bot instance
intents = discord.Intents.default()
intents.message_content = True
bot = commands.Bot(command_prefix="!", intents=intents)

# File to store conversation history
HISTORY_FILE = "ChatHist.json"

def normalize_message(message):
    """
    Normalize a single message to ensure it conforms to the required format:
      {
         "role": "user" or "model",
         "parts": [ {"text": <message_text>} ]
      }
    This function also removes any extraneous keys (e.g. a stray "role" inside a part).
    """
    # Determine the appropriate role from the message's top‐level "role"
    role = message.get("role")
    if role not in ["user", "model"]:
        # If not set (or invalid), try to extract from within parts—otherwise, default to "user"
        parts = message.get("parts", [])
        if parts and isinstance(parts[0], dict) and "role" in parts[0]:
            role = parts[0].pop("role")
            if role not in ["user", "model"]:
                role = "user"
        else:
            role = "user"
    # Normalize the parts: only include the "text" key for each part.
    normalized_parts = []
    for part in message.get("parts", []):
        normalized_parts.append({"text": part.get("text", "")})
    return {"role": role, "parts": normalized_parts}

def load_chat_history():
    """Load conversation history from file and normalize each message."""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r") as f:
                raw_history = json.load(f)
        except json.JSONDecodeError:
            raw_history = {}
    else:
        raw_history = {}
    
    normalized_history = {}
    for user_id, messages in raw_history.items():
        normalized_messages = []
        for message in messages:
            normalized_messages.append(normalize_message(message))
        normalized_history[user_id] = normalized_messages
    return normalized_history

def save_chat_history(history):
    """Save the (normalized) conversation history back to file."""
    with open(HISTORY_FILE, "w") as f:
        json.dump(history, f, indent=4)

def generate_content(prompt, user_id, max_tokens=5000):
    """
    Generates a response from the Gemini API using conversation history.
    
    Each message is structured like:
      { "role": "user" or "model", "parts": [{"text": "<message>"}] }
    
    The payload sent to Gemini is:
      {
         "contents": [list of messages],
         "generationConfig": {"maxOutputTokens": max_tokens}
      }
    """
    # Load (and normalize) current conversation history
    chat_hist = load_chat_history()
    key = str(user_id)
    user_history = chat_hist.get(key, [])
    
    # Append the new user message
    user_history.append({"role": "user", "parts": [{"text": prompt}]})
    
    # Limit the history to the last 6 messages (adjust as needed)
    if len(user_history) > 6:
        user_history = user_history[-6:]
    chat_hist[key] = user_history

    # Build the Gemini API payload
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={GEMINI_API_KEY}"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": user_history,
        "generationConfig": {"maxOutputTokens": max_tokens}
    }

    # Send the API request
    response = requests.post(url, headers=headers, json=payload)
    print("Status Code:", response.status_code)
    print("Response:", response.text)

    # Process the response if successful
    if response.status_code == 200:
        res_json = response.json()
        if "candidates" in res_json:
            model_text = res_json["candidates"][0]["content"]["parts"][0]["text"]
            # Append the Gemini response to the conversation history
            user_history.append({"role": "model", "parts": [{"text": model_text}]})
            chat_hist[key] = user_history
            save_chat_history(chat_hist)
            return model_text

    # Save updated history even if an error occurs (to preserve context)
    save_chat_history(chat_hist)
    return f"Error {response.status_code}: {response.text}"

@bot.command()
async def chat(ctx, *, prompt):
    """Handles the !chat command to generate a Gemini response using conversation history."""
    response_text = generate_content(prompt, ctx.author.id, max_tokens=100)
    await ctx.send(f"**Gemini says:** {response_text}")

@bot.command()
async def c(ctx, *, prompt):
    """Alias for the !chat command."""
    response_text = generate_content(prompt, ctx.author.id, max_tokens=100)
    await ctx.send(f"> {response_text}")

@bot.event
async def on_ready():
    print(f"Bot is live! {bot.user.name} is ready.")

bot.run(TOKEN)
